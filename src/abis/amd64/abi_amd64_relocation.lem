(** [abi_amd64_relocation] contains types and definitions relating to ABI
  * specific relocation functionality for the AMD64 ABI.
  *)

open import Basic_classes
open import Map
open import Maybe
open import Num
open import String

open import Error
open import Missing_pervasives

open import Elf_types_native_uint
open import Elf_file
open import Elf_header
open import Elf_relocation
open import Elf_symbol_table

open import Abi_utilities

(** x86-64 relocation types. *)

let r_x86_64_none : natural = 0
let r_x86_64_64 : natural = 1
let r_x86_64_pc32 : natural = 2
let r_x86_64_got32 : natural = 3
let r_x86_64_plt32 : natural = 4
let r_x86_64_copy : natural = 5
let r_x86_64_glob_dat : natural = 6
let r_x86_64_jump_slot : natural = 7
let r_x86_64_relative : natural = 8
let r_x86_64_gotpcrel : natural = 9
let r_x86_64_32 : natural = 10
let r_x86_64_32s : natural = 11
let r_x86_64_16 : natural = 12
let r_x86_64_pc16 : natural = 13
let r_x86_64_8 : natural = 14
let r_x86_64_pc8 : natural = 15
let r_x86_64_dtpmod64 : natural = 16
let r_x86_64_dtpoff64 : natural = 17
let r_x86_64_tpoff64 : natural = 18
let r_x86_64_tlsgd : natural = 19
let r_x86_64_tlsld : natural = 20
let r_x86_64_dtpoff32 : natural = 21
let r_x86_64_gottpoff : natural = 22
let r_x86_64_tpoff32 : natural = 23
let r_x86_64_pc64 : natural = 24
let r_x86_64_gotoff64 : natural = 25
let r_x86_64_gotpc32 : natural = 26
let r_x86_64_size32 : natural = 32
let r_x86_64_size64 : natural = 33
let r_x86_64_gotpc32_tlsdesc : natural = 34
let r_x86_64_tlsdesc_call : natural = 35
let r_x86_64_tlsdesc : natural = 36
let r_x86_64_irelative : natural = 37

(** [string_of_x86_64_relocation_type m] produces a string representation of the
  * relocation type [m].
  *)
val string_of_amd64_relocation_type : natural -> string
let string_of_amd64_relocation_type rel_type =
  if rel_type = r_x86_64_none then
    "R_X86_64_NONE"
  else if rel_type = r_x86_64_64 then
    "R_X86_64_64"
  else if rel_type = r_x86_64_pc32 then
    "R_X86_64_PC32"
  else if rel_type = r_x86_64_got32 then
    "R_X86_64_GOT32"
  else if rel_type = r_x86_64_plt32 then
    "R_X86_64_PLT32"
  else if rel_type = r_x86_64_copy then
    "R_X86_64_COPY"
  else if rel_type = r_x86_64_glob_dat then
    "R_X86_64_GLOB_DAT"
  else if rel_type = r_x86_64_jump_slot then
    "R_X86_64_JUMP_SLOT"
  else if rel_type = r_x86_64_relative then
    "R_X86_64_RELATIVE"
  else if rel_type = r_x86_64_gotpcrel then
    "R_X86_64_GOTPCREL"
  else if rel_type = r_x86_64_32 then
    "R_X86_64_32"
  else if rel_type = r_x86_64_32s then
    "R_X86_64_32S"
  else if rel_type = r_x86_64_16 then
    "R_X86_64_16"
  else if rel_type = r_x86_64_pc16 then
    "R_X86_64_PC16"
  else if rel_type = r_x86_64_8 then
    "R_X86_64_8"
  else if rel_type = r_x86_64_pc8 then
    "R_X86_64_PC8"
  else if rel_type = r_x86_64_dtpmod64 then
    "R_X86_64_DTPMOD64"
  else if rel_type = r_x86_64_dtpoff64 then
    "R_X86_64_DTPOFF64"
  else if rel_type = r_x86_64_tpoff64 then
    "R_X86_64_TPOFF64"
  else if rel_type = r_x86_64_tlsgd then
    "R_X86_64_TLSGD"
  else if rel_type = r_x86_64_tlsld then
    "R_X86_64_TLSLD"
  else if rel_type = r_x86_64_dtpoff32 then
    "R_X86_64_DTPOFF32"
  else if rel_type = r_x86_64_gottpoff then
    "R_X86_64_GOTTPOFF"
  else if rel_type = r_x86_64_tpoff32 then
    "R_X86_64_TPOFF32"
  else if rel_type = r_x86_64_pc64 then
    "R_X86_64_PC64"
  else if rel_type = r_x86_64_gotoff64 then
    "R_X86_64_GOTOFF64"
  else if rel_type = r_x86_64_gotpc32 then
    "R_X86_64_GOTPC32"
  else if rel_type = r_x86_64_size32 then
    "R_X86_64_SIZE32"
  else if rel_type = r_x86_64_size64 then
    "R_X86_64_SIZE64"
  else if rel_type = r_x86_64_gotpc32_tlsdesc then
    "R_X86_64_GOTPC32_TLSDESC"
  else if rel_type = r_x86_64_tlsdesc_call then
    "R_X86_64_TLSDESC_CALL"
  else if rel_type = r_x86_64_tlsdesc then
    "R_X86_64_TLSDESC"
  else if rel_type = r_x86_64_irelative then
    "R_X86_64_IRELATIVE"
  else
    "Invalid X86_64 relocation"

(** [width_of_x86_64_relocation m s] yields the width in bytes of the relocatable field, 
  * when resolving to a defined maybe symbol [s] (or Nothing, if weak).
  *)
val width_of_x86_64_relocation : natural -> maybe elf64_symbol_table_entry -> natural
let width_of_x86_64_relocation rel_type s =
  if rel_type = r_x86_64_none then 0
  else if rel_type = r_x86_64_64 then 8
  else if rel_type = r_x86_64_pc32 then 4
  else if rel_type = r_x86_64_got32 then 4
  else if rel_type = r_x86_64_plt32 then 4
  else if rel_type = r_x86_64_copy then match s with Nothing -> 0 | Just s -> natural_of_elf64_xword s.elf64_st_size end
  else if rel_type = r_x86_64_glob_dat then match s with Nothing -> 0 | Just s -> natural_of_elf64_xword s.elf64_st_size end (* CHECK *)
  else if rel_type = r_x86_64_jump_slot then 4 (* CHECK *)
  else if rel_type = r_x86_64_relative then 8 (* CHECK *)
  else if rel_type = r_x86_64_gotpcrel then 8 (* CHECK *)
  else if rel_type = r_x86_64_32 then 4
  else if rel_type = r_x86_64_32s then 4
  else if rel_type = r_x86_64_16 then 2
  else if rel_type = r_x86_64_pc16 then 2
  else if rel_type = r_x86_64_8 then 1
  else if rel_type = r_x86_64_pc8 then 1
  else if rel_type = r_x86_64_dtpmod64 then 8 (* CHECK *)
  else if rel_type = r_x86_64_dtpoff64 then 8 (* CHECK *)
  else if rel_type = r_x86_64_tpoff64 then 8 (* CHECK *)
  else if rel_type = r_x86_64_tlsgd then 8 (* CHECK *)
  else if rel_type = r_x86_64_tlsld then 8 (* CHECK *)
  else if rel_type = r_x86_64_dtpoff32 then 4 (* CHECK *)
  else if rel_type = r_x86_64_gottpoff then 8 (* CHECK *)
  else if rel_type = r_x86_64_tpoff32 then 4 (* CHECK *)
  else if rel_type = r_x86_64_pc64 then 8
  else if rel_type = r_x86_64_gotoff64 then 8
  else if rel_type = r_x86_64_gotpc32 then 4
  else if rel_type = r_x86_64_size32 then 4
  else if rel_type = r_x86_64_size64 then 8
  else if rel_type = r_x86_64_gotpc32_tlsdesc then 4 (* CHECK *)
  else if rel_type = r_x86_64_tlsdesc_call then 4 (* CHECK *)
  else if rel_type = r_x86_64_tlsdesc then 8 (* CHECK *)
  else if rel_type = r_x86_64_irelative then 8 (* CHECK *)
  else 0 (* invalid *)

(** [abi_amd64_apply_relocation rel val_map ef]
  * calculates the effect of a relocation of type [rel] using relevant addresses,
  * offsets and fields represented by [b_val], [g_val], [got_val], [l_val], [p_val],
  * [s_val] and [z_val], stored in [val_map] with "B", "G", and so on as string
  * keys, which are:
  *
  *    - B  : Base address at which a shared-object has been loaded into memory
  *           during execution.
  *    - G  : Represents the offset into the GOT at which the relocation's entry
  *           will reside during execution.
  *    - GOT: Address of the GOT.
  *    - L  : Represents the address or offset of the PLT entry for a symbol.
  *    - P  : Represents the address or offset of the storage unit being
  *           relocated.
  *    - S  : Represents the value of the symbol whose index resides in the
  *           relocation entry.
  *    - Z  : Represents the size of the symbol whose index resides in the
  *           relocation entry.
  *
  * More details of the above can be found in the AMD64 ABI document's chapter
  * on relocations.
  *
  * The [abi_amd64_apply_relocation] function returns a relocation frame, either
  * indicating that the relocation is a copy relocation, or that some calculation
  * must be carried out at a certain location.  See the comment above the
  * [relocation_frame] type in [Abi_utilities.lem] for more details.
  *)
val abi_amd64_apply_relocation : elf64_relocation_a -> val_map -> elf64_file
  -> error (relocation_frame elf64_addr integer)
let abi_amd64_apply_relocation rel val_map ef =
  if is_elf64_relocatable_file ef.elf64_file_header then
    let rel_type = elf64_relocation_r_type rel.elf64_ra_info in
    let a_val    = integer_of_elf64_sxword rel.elf64_ra_addend in
      (** No width, No calculation *)
      if rel_type = r_x86_64_none then
        return (NoCopy (Map.empty))
      (** Width: 64 Calculation: S + A *)
      else if rel_type = r_x86_64_64 then
        lookupM "S" val_map >>= fun s_val ->
      	let result = Lift (s_val + a_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (NoCopy (Map.singleton addr (result, I64, CannotFail)))
      (** Width: 32 Calculation: S + A - P *)
      else if rel_type = r_x86_64_pc32 then
        lookupM "S" val_map >>= fun s_val ->
        lookupM "P" val_map >>= fun p_val ->
      	let result = Lift ((s_val + a_val) - p_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (NoCopy (Map.singleton addr (result, I32, CanFail)))
      (** Width: 32 Calculation: G + A *)
  		else if rel_type = r_x86_64_got32 then
  		  lookupM "G" val_map >>= fun g_val ->
      	let result = Lift (g_val + a_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (NoCopy (Map.singleton addr (result, I32, CanFail)))
      (** Width: 32 Calculation: L + A - P *)
  		else if rel_type = r_x86_64_plt32 then
  		  lookupM "L" val_map >>= fun l_val ->
  		  lookupM "P" val_map >>= fun p_val ->
  		  let result = Lift ((l_val + a_val) - p_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (NoCopy (Map.singleton addr (result, I32, CanFail)))
    	(** No width, No calculation *)
		  else if rel_type = r_x86_64_copy then
		    return Copy
		  (** Width: 64 Calculation: S *)
		  else if rel_type = r_x86_64_glob_dat then
      	let result = Lift s_val in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I64, CannotFail))
		  (** Width: 64 Calculation: S *)
		  else if rel_type = r_x86_64_jump_slot then
      	let result = Lift s_val in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I64, CannotFail))
		  (** Width: 64 Calculation: B + A *)
		  else if rel_type = r_x86_64_relative then
      	let result = Lift (b_val + a_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I64, CannotFail))
		  (** Width: 32 Calculation: G + GOT + A - P *)
		  else if rel_type = r_x86_64_gotpcrel then
      	let result = Lift ((g_val + got_val + a_val) - p_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I32, CanFail))
		  (** Width: 32 Calculation: S + A *)
		  else if rel_type = r_x86_64_32 then
      	let result = Lift (s_val + a_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I32, CanFail))
		  (** Width: 32 Calculation: S + A *)
		  else if rel_type = r_x86_64_32s then
      	let result = Lift (s_val + a_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I32, CanFail))
		  (** Width: 16 Calculation: S + A *)
		  else if rel_type = r_x86_64_16 then
      	let result = Lift (s_val + a_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I16, CanFail))
		  (** Width: 16 Calculation: S + A - P *)
		  else if rel_type = r_x86_64_pc16 then
      	let result = Lift ((s_val + a_val) - p_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I16, CanFail))
		  (** Width: 8 Calculation: S + A *)
		  else if rel_type = r_x86_64_8 then
      	let result = Lift (s_val + a_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I8, CanFail))
      (** Width 8: Calculation: S + A - P *)
		  else if rel_type = r_x86_64_pc8 then
      	let result = Lift ((s_val + a_val) - p_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I8, CanFail))
      (** Width: 64 *)
		  else if rel_type = r_x86_64_dtpmod64 then
		    fail "abi_amd64_apply_relocation: r_x86_64_dtpmod64 not implemented"
      (** Width: 64 *)
		  else if rel_type = r_x86_64_dtpoff64 then
		    fail "abi_amd64_apply_relocation: r_x86_64_dtpoff64 not implemented"
      (** Width: 64 *)
		  else if rel_type = r_x86_64_tpoff64 then
		    fail "abi_amd64_apply_relocation: r_x86_64_tpoff64 not implemented"
      (** Width: 32 *)
		  else if rel_type = r_x86_64_tlsgd then
		    fail "abi_amd64_apply_relocation: r_x86_64_tlsgd not implemented"
      (** Width: 32 *)
		  else if rel_type = r_x86_64_tlsld then
		    fail "abi_amd64_apply_relocation: r_x86_64_tlsld not implemented"
      (** Width: 32 *)
		  else if rel_type = r_x86_64_dtpoff32 then
		    fail "abi_amd64_apply_relocation: r_x86_64_dtpoff32 not implemented"
      (** Width: 32 *)
		  else if rel_type = r_x86_64_gottpoff then
		    fail "abi_amd64_apply_relocation: r_x86_64_gottpoff not implemented"
      (** Width: 32 *)
		  else if rel_type = r_x86_64_tpoff32 then
		    fail "abi_amd64_apply_relocation: r_x86_64_tpoff32 not implemented"
		  (** Width: 64 Calculation: S + A - P *)
		  else if rel_type = r_x86_64_pc64 then
      	let result = Lift ((s_val + a_val) - p_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I64, CannotFail))
		  (** Width: 64 Calculation: S + A - GOT *)
		  else if rel_type = r_x86_64_gotoff64 then
      	let result = Lift ((s_val + a_val) - got_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I64, CannotFail))
		  (** Width: 32 Calculation: GOT + A - P *)
		  else if rel_type = r_x86_64_gotpc32 then
      	let result = Lift ((got_val + a_val) - p_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I32, CanFail))
		  (** Width: 32 Calculation: Z + A *)
		  else if rel_type = r_x86_64_size32 then
      	let result = Lift (z_val + a_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I32, CanFail))
		  (** Width: 64 Calculation: Z + A *)
		  else if rel_type = r_x86_64_size64 then
      	let result = Lift (z_val + a_val) in
      	let addr   = rel.elf64_ra_offset in
      		return (Map.singleton addr (result, I64, CannotFail))
      (** Width: 32 *)
		  else if rel_type = r_x86_64_gotpc32_tlsdesc then
		    fail "abi_amd64_apply_relocation: r_x86_64_gotpc32_tlsdesc not implemented"
      (** No width *)
		  else if rel_type = r_x86_64_tlsdesc_call then
		    fail "abi_amd64_apply_relocation: r_x86_64_tlsdesc_call not implemented"
		  (** Width: 64X2 *)
		  else if rel_type = r_x86_64_tlsdesc then
		    fail "abi_amd64_apply_relocation: r_x86_64_tlsdesc not implemented"
		  (** Calculation: indirect(B + A) *)
		  else if rel_type = r_x86_64_irelative then
		    let result = Apply(Indirect, Lift(b_val + a_val)) in
		    let addr   = rel.elf64_ra_offset in
		      return (Map.singleton addr (result, I64, CannotFail))
		  else
		  	fail "abi_amd64_apply_relocation: invalid relocation type"
  else
  	fail "abi_amd64_apply_relocation: not a relocatable file"
